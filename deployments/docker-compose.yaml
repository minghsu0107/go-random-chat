version: '3'
services:
  reverse-proxy:
    image: traefik:v2.3
    restart: always
    command:
      - "--entryPoints.web.address=:80"
      - "--api.insecure=true"
      - "--providers.docker"
      - "--providers.docker.exposedbydefault=false"
      - --accesslog=true # output log to stdout
      - --tracing=true
      - --tracing.jaeger=true
      - --tracing.jaeger.collector.endpoint=http://jaeger:14268/api/traces?format=jaeger.thrift
      - --tracing.jaeger.traceContextHeaderName=uber-trace-id
      - --tracing.jaeger.gen128Bit
      - --tracing.jaeger.samplingParam=1.0
    ports:
      - 80:80
      - 8080:8080
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
  web:
    image: minghsu0107/random-chat-web:kafka
    restart: always
    expose:
      - "80"
    environment:
      WEB_HTTP_SERVER_PORT: "80"
      OBSERVABILITY_PROMETHEUS_PORT: "8080"
      OBSERVABILITY_TRACING_JAEGERURL: http://jaeger:14268/api/traces
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.rcweb.rule=PathPrefix(`/`)"
      - "traefik.http.routers.rcweb.entrypoints=web"
      - "traefik.http.routers.rcweb.service=rcweb"
      - "traefik.http.services.rcweb.loadbalancer.server.port=80"
  random-chat:
    image: minghsu0107/random-chat-api:kafka
    restart: always
    expose:
      - "80"
      - "4000"
    command:
      - chat
    environment:
      CHAT_HTTP_SERVER_PORT: "80"
      CHAT_HTTP_SERVER_MAXCONN: "200"
      CHAT_HTTP_SERVER_SWAG: "true"
      CHAT_GRPC_SERVER_PORT: "4000"
      CHAT_GRPC_CLIENT_USER_ENDPOINT: "reverse-proxy:80"
      CHAT_GRPC_CLIENT_FORWARDER_ENDPOINT: "reverse-proxy:80"
      CHAT_MESSAGE_MAXNUM: "5000"
      CHAT_MESSAGE_PAGINATIONNUM: "5000"
      CHAT_MESSAGE_MAXSIZEBYTE: "4096"
      CHAT_JWT_SECRET: ${JWT_SECRET}
      CHAT_JWT_EXPIRATIONSECOND: "86400"
      KAFKA_ADDRS: kafka:9092
      KAFKA_VERSION: "3.0.1"
      CASSANDRA_HOSTS: cassandra
      CASSANDRA_PORT: "9042"
      CASSANDRA_USER: ming
      CASSANDRA_PASSWORD: cassandrapass
      CASSANDRA_KEYSPACE: randomchat
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_ADDRS: redis-node-0:6379,redis-node-1:6379,redis-node-2:6379,redis-node-3:6379,redis-node-4:6379,redis-node-5:6379
      REDIS_EXPIRATIONHOUR: "24"
      OBSERVABILITY_PROMETHEUS_PORT: "8080"
      OBSERVABILITY_TRACING_JAEGERURL: http://jaeger:14268/api/traces
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.random-chat.rule=PathPrefix(`/api/chat`)"
      - "traefik.http.routers.random-chat.entrypoints=web"
      - "traefik.http.routers.random-chat.service=random-chat"
      - "traefik.http.services.random-chat.loadbalancer.server.port=80"
      - "traefik.http.routers.random-chat-grpc.rule=Headers(`content-type`,`application/grpc`) && Headers(`service-id`, `chat`)"
      - "traefik.http.routers.random-chat-grpc.entrypoints=web"
      - "traefik.http.routers.random-chat-grpc.service=random-chat-grpc"
      - "traefik.http.services.random-chat-grpc.loadbalancer.server.port=4000"
      - "traefik.http.services.random-chat-grpc.loadbalancer.server.scheme=h2c"
    depends_on:
      - zookeeper
      - kafka
  forwarder:
    image: minghsu0107/random-chat-api:kafka
    restart: always
    expose:
      - "4000"
    command:
      - forwarder
    environment:
      FORWARDER_GRPC_SERVER_PORT: "4000"
      KAFKA_ADDRS: kafka:9092
      KAFKA_VERSION: "3.0.1"
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_ADDRS: redis-node-0:6379,redis-node-1:6379,redis-node-2:6379,redis-node-3:6379,redis-node-4:6379,redis-node-5:6379
      REDIS_EXPIRATIONHOUR: "24"
      OBSERVABILITY_PROMETHEUS_PORT: "8080"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.forwarder-grpc.rule=Headers(`content-type`,`application/grpc`) && Headers(`service-id`, `forwarder`)"
      - "traefik.http.routers.forwarder-grpc.entrypoints=web"
      - "traefik.http.routers.forwarder-grpc.service=forwarder-grpc"
      - "traefik.http.services.forwarder-grpc.loadbalancer.server.port=4000"
      - "traefik.http.services.forwarder-grpc.loadbalancer.server.scheme=h2c"
    depends_on:
      - zookeeper
      - kafka
  match:
    image: minghsu0107/random-chat-api:kafka
    restart: always
    expose:
      - "80"
    command:
      - match
    environment:
      MATCH_HTTP_SERVER_PORT: "80"
      MATCH_HTTP_SERVER_MAXCONN: "200"
      MATCH_HTTP_SERVER_SWAG: "true"
      MATCH_GRPC_CLIENT_CHAT_ENDPOINT: "reverse-proxy:80"
      MATCH_GRPC_CLIENT_USER_ENDPOINT: "reverse-proxy:80"
      KAFKA_ADDRS: kafka:9092
      KAFKA_VERSION: "3.0.1"
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_ADDRS: redis-node-0:6379,redis-node-1:6379,redis-node-2:6379,redis-node-3:6379,redis-node-4:6379,redis-node-5:6379
      REDIS_EXPIRATIONHOUR: "24"
      OBSERVABILITY_PROMETHEUS_PORT: "8080"
      OBSERVABILITY_TRACING_JAEGERURL: http://jaeger:14268/api/traces
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.match.rule=PathPrefix(`/api/match`)"
      - "traefik.http.routers.match.entrypoints=web"
      - "traefik.http.routers.match.service=match"
      - "traefik.http.services.match.loadbalancer.server.port=80"
  uploader:
    image: minghsu0107/random-chat-api:kafka
    restart: always
    depends_on:
      - minio
    expose:
      - "80"
    command:
      - uploader
    environment:
      UPLOADER_HTTP_SERVER_PORT: "80"
      UPLOADER_HTTP_SERVER_SWAG: "true"
      UPLOADER_HTTP_SERVER_MAXBODYBYTE: "67108864"
      UPLOADER_HTTP_SERVER_MAXMEMORYBYTE: "16777216"
      UPLOADER_S3_ENDPOINT: http://minio:9000
      UPLOADER_S3_REGION: us-east-1
      UPLOADER_S3_BUCKET: myfilebucket
      UPLOADER_S3_ACCESSKEY: testaccesskey
      UPLOADER_S3_SECRETKEY: testsecret
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_ADDRS: redis-node-0:6379,redis-node-1:6379,redis-node-2:6379,redis-node-3:6379,redis-node-4:6379,redis-node-5:6379
      OBSERVABILITY_PROMETHEUS_PORT: "8080"
      OBSERVABILITY_TRACING_JAEGERURL: http://jaeger:14268/api/traces
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.uploader.rule=PathPrefix(`/api/uploader`)"
      - "traefik.http.routers.uploader.entrypoints=web"
      - "traefik.http.routers.uploader.service=uploader"
      - "traefik.http.services.uploader.loadbalancer.server.port=80"
      - "traefik.http.routers.uploader.middlewares=channel-auth"
      - "traefik.http.middlewares.channel-auth.forwardauth.address=http://random-chat/api/chat/forwardauth"
      - "traefik.http.middlewares.channel-auth.forwardauth.authResponseHeaders=X-Channel-Id"
      - "traefik.http.routers.uploader-swagger.rule=PathPrefix(`/api/uploader/swagger`)"
      - "traefik.http.routers.uploader-swagger.entrypoints=web"
      - "traefik.http.routers.uploader-swagger.service=uploader-swagger"
      - "traefik.http.services.uploader-swagger.loadbalancer.server.port=80"
  user:
    image: minghsu0107/random-chat-api:kafka
    restart: always
    expose:
      - "80"
    command:
      - user
    environment:
      USER_HTTP_SERVER_PORT: "80"
      USER_HTTP_SERVER_SWAG: "true"
      USER_GRPC_SERVER_PORT: "4000"
      USER_OAUTH_GOOGLE_CLIENTID: ${USER_OAUTH_GOOGLE_CLIENTID}
      USER_OAUTH_GOOGLE_CLIENTSECRET: ${USER_OAUTH_GOOGLE_CLIENTSECRET}
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_ADDRS: redis-node-0:6379,redis-node-1:6379,redis-node-2:6379,redis-node-3:6379,redis-node-4:6379,redis-node-5:6379
      REDIS_EXPIRATIONHOUR: "24"
      OBSERVABILITY_PROMETHEUS_PORT: "8080"
      OBSERVABILITY_TRACING_JAEGERURL: http://jaeger:14268/api/traces
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.user.rule=PathPrefix(`/api/user`)"
      - "traefik.http.routers.user.entrypoints=web"
      - "traefik.http.routers.user.service=user"
      - "traefik.http.services.user.loadbalancer.server.port=80"
      - "traefik.http.routers.user-grpc.rule=Headers(`content-type`,`application/grpc`) && Headers(`service-id`, `user`)"
      - "traefik.http.routers.user-grpc.entrypoints=web"
      - "traefik.http.routers.user-grpc.service=user-grpc"
      - "traefik.http.services.user-grpc.loadbalancer.server.port=4000"
      - "traefik.http.services.user-grpc.loadbalancer.server.scheme=h2c"
  minio:
    image: minio/minio:RELEASE.2023-07-11T21-29-34Z
    volumes:
      - minio_data:/export
    command: 
      - server
      - /export
      - --console-address
      - ":9001"
    environment:
      MINIO_ROOT_USER: testaccesskey
      MINIO_ROOT_PASSWORD: testsecret
      MINIO_API_ROOT_ACCESS: "on"
      # FQDN the MinIO Console should use for connecting to the MinIO Server
      MINIO_SERVER_URL: http://minio:9000
    ports:
      - "9000:9000"
      - "9001:9001"
  createbucket:
    image: minio/mc:RELEASE.2023-07-11T23-30-44Z
    restart: on-failure:5
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      set -e;
      /usr/bin/mc config host add myminio http://minio:9000 testaccesskey testsecret;
      /usr/bin/mc mb myminio/myfilebucket;
      /usr/bin/mc anonymous set private myminio/myfilebucket;
      exit 0;
      "
  prometheus:
    image: prom/prometheus:v2.45.0
    restart: always
    volumes:
      - ./prometheus/prometheus.yaml:/etc/prometheus/prometheus.yaml
    command: 
      - --config.file=/etc/prometheus/prometheus.yaml
      - --enable-feature=exemplar-storage
    ports:
      - 9090:9090
  jaeger:
    image: jaegertracing/all-in-one:1.22
    restart: always
    ports:
      - 14268:14268
      - 16686:16686
  redis-node-0:
    image: docker.io/bitnami/redis-cluster:7.0
    restart: always
    volumes:
      - redis-cluster_data-0:/bitnami/redis/data
    environment:
      - 'REDIS_PASSWORD=${REDIS_PASSWORD}'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2 redis-node-3 redis-node-4 redis-node-5'

  redis-node-1:
    image: docker.io/bitnami/redis-cluster:7.0
    restart: always
    volumes:
      - redis-cluster_data-1:/bitnami/redis/data
    environment:
      - 'REDIS_PASSWORD=${REDIS_PASSWORD}'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2 redis-node-3 redis-node-4 redis-node-5'

  redis-node-2:
    image: docker.io/bitnami/redis-cluster:7.0
    restart: always
    volumes:
      - redis-cluster_data-2:/bitnami/redis/data
    environment:
      - 'REDIS_PASSWORD=${REDIS_PASSWORD}'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2 redis-node-3 redis-node-4 redis-node-5'

  redis-node-3:
    image: docker.io/bitnami/redis-cluster:7.0
    restart: always
    volumes:
      - redis-cluster_data-3:/bitnami/redis/data
    environment:
      - 'REDIS_PASSWORD=${REDIS_PASSWORD}'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2 redis-node-3 redis-node-4 redis-node-5'

  redis-node-4:
    image: docker.io/bitnami/redis-cluster:7.0
    restart: always
    volumes:
      - redis-cluster_data-4:/bitnami/redis/data
    environment:
      - 'REDIS_PASSWORD=${REDIS_PASSWORD}'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2 redis-node-3 redis-node-4 redis-node-5'

  redis-node-5:
    image: docker.io/bitnami/redis-cluster:7.0
    restart: always
    volumes:
      - redis-cluster_data-5:/bitnami/redis/data
    depends_on:
      - redis-node-0
      - redis-node-1
      - redis-node-2
      - redis-node-3
      - redis-node-4
    environment:
      - 'REDIS_PASSWORD=${REDIS_PASSWORD}'
      - 'REDISCLI_AUTH=${REDIS_PASSWORD}'
      - 'REDIS_CLUSTER_REPLICAS=1'
      - 'REDIS_NODES=redis-node-0 redis-node-1 redis-node-2 redis-node-3 redis-node-4 redis-node-5'
      - 'REDIS_CLUSTER_CREATOR=yes'
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181   
  kafka:
    image: confluentinc/cp-kafka:7.0.1
    restart: unless-stopped
    environment:
      KAFKA_LOG_RETENTION_MINUTES: 1440 # save data for 24hrs
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      # This is required when you are running with a single-node cluster
      # specify the replication factor for the __consumer_offsets topic
      # __consumer_offsets topic preserves consumer offsets when consumer group commits offsets to Kafka
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # when applications attempt to produce, consume, or fetch metadata for a non-existent topic, 
      # Kafka will automatically create the topic with the default replication factor and number of partitions
      # which is true by default
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    depends_on:
      - zookeeper
  cassandra:
    image: docker.io/bitnami/cassandra:4.0
    restart: always
    ports:
      - 9042:9042
    volumes:
      - cassandra_data:/bitnami
      - ./cassandra:/docker-entrypoint-initdb.d
    environment:
      - CASSANDRA_SEEDS=cassandra
      - CASSANDRA_PASSWORD_SEEDER=yes
      - CASSANDRA_USER=ming
      - CASSANDRA_PASSWORD=cassandrapass
volumes:
  minio_data:
  cassandra_data:
  redis-cluster_data-0:
  redis-cluster_data-1:
  redis-cluster_data-2:
  redis-cluster_data-3:
  redis-cluster_data-4:
  redis-cluster_data-5:
